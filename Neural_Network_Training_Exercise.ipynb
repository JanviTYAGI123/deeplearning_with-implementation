{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Problem Statement: **Training in Agricultural Company**\n",
        "\n",
        "### In this chapter, you’ll explore the foundational aspects of training neural networks in AI-oriented Agricultural company. You’ll work as an AI engineer to train models that solve critical challenges in different domains. Along the way, you’ll learn about gradient descent, batch processing, and training neural networks from scratch.\n",
        "\n",
        "References:\n",
        "* Column Stack (Numpy) [link](https://numpy.org/doc/stable/reference/generated/numpy.column_stack.html)\n",
        "\n",
        "* PyTorch Tensors (PyTorch) [link](https://pytorch.org/tutorials/beginner/introyt/tensors_deeper_tutorial.html)\n",
        "\n",
        "* Sequential (PyTorch) [link](https://pytorch.org/docs/stable/generated/torch.nn.Sequential.html)"
      ],
      "metadata": {
        "id": "AMWT24IcCq1N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Imports and CUDA"
      ],
      "metadata": {
        "id": "w7qTZ-o7DRTP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QVRQzxnKCbRL",
        "outputId": "00ad97d5-4ddf-4999-d571-d98e79464cef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Check if CUDA (GPU) is available\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Task1: Predicting Equipment Costs**\n",
        "\n",
        "The AI Agriculture Company is developing a tool to predict the cost of manufacturing its new agricultural equipment. The cost is directly proportional to the square of the material used. Your task is to compute and predict the cost, and debug the gradients of the implemented backpropagation process.\n",
        "\n",
        "Use when required: $$ f(x) = x^2$$"
      ],
      "metadata": {
        "id": "VRPCoIeNOAPw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step1:** Define the Problem\n",
        "\n",
        "Assume the material required is represented as a single feature: **material_amount**. For simplicity:\n",
        "\n",
        "* **Input:** material_amount (a tensor of size (1, 1)) — e.g., 5 units of material.\n",
        "* **Target cost:** material_amount ** 2 — the cost of producing the equipment."
      ],
      "metadata": {
        "id": "JDYY9uleUxBC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Material amount as input (e.g., 5 units)\n",
        "\n",
        "\n",
        "# Target cost (cost = material_amount ** 2)"
      ],
      "metadata": {
        "id": "JIih0kRoViAx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step2:** Set Up the Model\n",
        "\n",
        "Use a single-layer linear model to predict the cost. The model should:\n",
        "\n",
        "* Take material_amount as input.\n",
        "* Output the predicted cost (scalar)."
      ],
      "metadata": {
        "id": "MbRa2fmNVic8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Start with random weights and zero biases"
      ],
      "metadata": {
        "id": "x2PbKdlmV5ir"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step3:** Compute Loss\n",
        "\n",
        "Use Mean Squared Error **(MSE)** to calculate the loss between the predicted and actual costs."
      ],
      "metadata": {
        "id": "y4mPVdW0V5_9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Loss function: Mean Squared Error (MSE)"
      ],
      "metadata": {
        "id": "IMRhR4-5WJgS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step4:** Backpropagation\n",
        "\n",
        "* Write the gradient descent process step-by-step.\n",
        "* Manually compute the gradients of the loss with respect to the model's weights and biases using the chain rule.\n"
      ],
      "metadata": {
        "id": "p3KtHjd2WJ7V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the gradient of the loss w.r.t. predicted_cost\n",
        "\n",
        "\n",
        "# Calculate the gradient of predicted_cost w.r.t. weight and bias"
      ],
      "metadata": {
        "id": "ury9YtJbxjxa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step5:** Verify Gradients\n",
        "\n",
        "Use **torch.autograd** to compute gradients automatically and compare them with your manual calculations.\n",
        "\n",
        "You can use **allclose** to check whether all elements of two tensors are approximately equal, within a specified tolerance.\n",
        "\n",
        "https://pytorch.org/docs/stable/generated/torch.allclose.html"
      ],
      "metadata": {
        "id": "vQkAqhsmWY1-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Code Here"
      ],
      "metadata": {
        "id": "CWS7RR2eXIC1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "U56K7C-qQ5_L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Task2: Optimizing Equipment Production with Neural Networks**\n",
        "\n",
        "The AI Agriculture Company wants to predict the efficiency of manufacturing equipment based on two input features:\n",
        "\n",
        "* Weekly hours spent on machine maintenance\n",
        "* Weekly hours spent on training factory workers.\n",
        "\n",
        "The company believes these two factors significantly impact production efficiency, which is represented as a score between 0 and 1. Your task is to build and train a simple neural network to predict this efficiency score."
      ],
      "metadata": {
        "id": "owGLtVZQTRsG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 1:** Dataset Details\n",
        "\n",
        "Simulate a dataset with the following properties:\n",
        "\n",
        "* Feature 1: Machine Maintenance Hours (range: 5 to 50 hours).\n",
        "* Feature 2: Training Hours for Workers (range: 2 to 20 hours).\n",
        "* Target Output: Efficiency score calculated as:\n",
        "\n",
        "$$ Efficiency Score= (0.4⋅Maintenance Hours+0.6⋅Training Hours)/5$$\n",
        "​\n",
        "\n"
      ],
      "metadata": {
        "id": "ObFXxToqZudV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Complete the code here\n",
        "np.random.seed(42)\n",
        "machine_maintenance_hours =   # Maintenance hours\n",
        "training_hours =              # Training hours\n",
        "efficiency_score =   # Efficiency score\n",
        "\n",
        "# Combine into a dataset\n",
        "X = np.column_stack((machine_maintenance_hours, training_hours))\n",
        "y = efficiency_score.reshape(-1, 1)\n",
        "\n"
      ],
      "metadata": {
        "id": "uhIRf13wTiFb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 2**: Split the dataset into training (80%) and validation (20%) sets."
      ],
      "metadata": {
        "id": "_8z-ELN0aIua"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Code Here"
      ],
      "metadata": {
        "id": "aRFzPKFdaajZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step3:** Normalize input features to improve training stability."
      ],
      "metadata": {
        "id": "nHskK6xHabGi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_val, y_train, y_val = # Code Here"
      ],
      "metadata": {
        "id": "0AfJlpOparCh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert data to PyTorch tensors\n",
        "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
        "y_train = torch.tensor(y_train, dtype=torch.float32)\n",
        "X_val = torch.tensor(X_val, dtype=torch.float32)\n",
        "y_val = torch.tensor(y_val, dtype=torch.float32)"
      ],
      "metadata": {
        "id": "PDGeXcisuvgm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step4:** Define a neural network with the following structure:\n",
        "\n",
        "* Input Layer: 2 neurons (for the two input features).\n",
        "* Hidden Layer: 5 neurons with ReLU activation.\n",
        "* Output Layer: 1 neuron with sigmoid activation (to output a value between 0 and 1).\n"
      ],
      "metadata": {
        "id": "9QTYqeJra68l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = nn.Sequential(\n",
        "    nn.Linear(2, 5),  # 2 input features, 5 hidden neurons\n",
        "    nn.ReLU(),        # ReLU activation\n",
        "    nn.Linear(5, 1),  # 1 output neuron\n",
        "    nn.Sigmoid()      # Sigmoid activation for efficiency score\n",
        ")"
      ],
      "metadata": {
        "id": "uXr1hLVwa0wL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step5**: Train the network using:\n",
        "\n",
        "* **Optimizers**: SGD.\n",
        "* **Epochs**: 200.\n",
        "* **Learning Rates**: 0.01."
      ],
      "metadata": {
        "id": "IvJP8mjca8EP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, loss_fn, optimizer, X, y, X_val, y_val, epochs):\n",
        "  # Code Here\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Step 6: Train and evaluate the model\n",
        "epochs =\n",
        "learning_rate ="
      ],
      "metadata": {
        "id": "s9tmzV-IbDgR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step6:**  Plot and analyze the convergence curves for training and validation loss"
      ],
      "metadata": {
        "id": "3w6lR90ebD_i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Code Here\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(train_losses, label=\"Training Loss\")\n",
        "plt.plot(val_losses, label=\"Validation Loss\", linestyle=\"--\")\n",
        "plt.title(\"Loss Convergence\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "psR_lEurbNIp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Bonus:** Modify epochs to 500 and learning rate to 0.05 and analyse the graph"
      ],
      "metadata": {
        "id": "2aa7BLa95gBY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "qjL-YESATyt_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Task4: Predicting Crop Yield in AgroTech**\n",
        "\n",
        "In AgroTech, an agriculture-focused town, farmers rely on AI systems to predict crop yields based on weather and soil data.\n",
        "\n",
        "Your task is to build and train a neural network to predict Crop Yield (tons/ha) using features from the provided dataset **(agriculture_dataset_codebasics_DL.csv)**."
      ],
      "metadata": {
        "id": "mrJ4LHZiTz5a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Dataset Overview**\n",
        "\n",
        "The agriculture_dataset.csv file contains the following features:\n",
        "\n",
        "* Temperature (C): Average temperature during the growing season.\n",
        "\n",
        "* Rainfall (mm): Total rainfall during the growing season.\n",
        "\n",
        "* Soil_pH: Soil acidity (range: 0-14).\n",
        "\n",
        "* Nitrogen (mg/kg): Nitrogen content in the soil.\n",
        "\n",
        "* Irrigation_Hours: Total hours of irrigation during the growing season.\n",
        "\n",
        "* Fertilizer_Usage (kg/ha): Total fertilizer used per hectare.\n",
        "\n",
        "* Crop_Yield (tons/ha): Target variable representing the crop yield."
      ],
      "metadata": {
        "id": "DOcZzq94iTCA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Goal**\n",
        "\n",
        "Train a neural network to predict the crop yield using Batch Gradient Descent, Mini-Batch Gradient Descent, and Stochastic Gradient Descent.\n",
        "\n",
        "Compare their performance by plotting loss convergence over epochs."
      ],
      "metadata": {
        "id": "ZFGxLGhiir-9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 1:** Load and split the dataset"
      ],
      "metadata": {
        "id": "KrxibUQ5iz7w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset\n",
        "\n",
        "\n",
        "# Split data into features and target\n"
      ],
      "metadata": {
        "id": "aiPmoJGHi1jb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 2:** Normalize the input features to a range of 0-1 and perform an **80%-20%** train-validation split."
      ],
      "metadata": {
        "id": "BWuxNl5ii2IF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Code"
      ],
      "metadata": {
        "id": "-zCs0SbSi5Az"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert data to PyTorch Tensors\n",
        "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
        "y_train = torch.tensor(y_train, dtype=torch.float32)\n",
        "X_val = torch.tensor(X_val, dtype=torch.float32)\n",
        "y_val = torch.tensor(y_val, dtype=torch.float32)"
      ],
      "metadata": {
        "id": "ZfARwFEbv9_h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 3:** Define a neural network architecture\n",
        "\n",
        "**Input:** 6 features (Temperature, Rainfall, Soil pH, Nitrogen, Irrigation Hours, Fertilizer Usage).\n",
        "\n",
        "**Hidden Layer:** 10 neurons with ReLU activation.\n",
        "\n",
        "**Output:** 1 neuron with linear activation (for regression)."
      ],
      "metadata": {
        "id": "9d3pW6ZGi6X5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Code Here"
      ],
      "metadata": {
        "id": "anJo6ifrkI7-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 4:** Train the network using\n",
        "\n",
        "Batch Gradient Descent (GD):Update weights after processing the entire dataset.\n",
        "\n",
        "Mini-Batch Gradient Descent: Update weights after processing batches of size 16.\n",
        "\n",
        "Stochastic Gradient Descent (SGD): Update weights after every data point."
      ],
      "metadata": {
        "id": "_Rcfk3Y3kJsX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training function for different GD methods\n",
        "def train_model(optimizer, X, y, epochs=50, batch_size=None):\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Train the model using Batch GD\n",
        "\n",
        "\n",
        "# Train the model using Mini-Batch GD\n",
        "\n",
        "\n",
        "# Train the model using Stochastic GD"
      ],
      "metadata": {
        "id": "ytTSQWLWkU_A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 5:** Plot the loss over epochs for each method."
      ],
      "metadata": {
        "id": "ZrVyXVFlkaKv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(losses_batch, label='Batch GD', marker='o')\n",
        "plt.plot(losses_mini_batch, label='Mini-Batch GD', marker='x')\n",
        "plt.plot(losses_sgd, label='Stochastic GD', marker='^')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Gradient Descent Strategies: Loss Convergence')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "gbNfMhYikeyC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 6:** Evaluate the model's Mean Squared Error (MSE) on the validation set."
      ],
      "metadata": {
        "id": "Sl0hir7okfXC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "# Code Here"
      ],
      "metadata": {
        "id": "cwhsjoxskknr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}